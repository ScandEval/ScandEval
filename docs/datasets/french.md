# üá´üá∑ French

This is an overview of all the datasets used in the French part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.


## Sentiment Classification

### Allocine

This dataset was published in [this Github
repository](https://github.com/TheophileBlard/french-sentiment-analysis-with-bert) and
features reviews from the French movie review website Allocine. The reviews range from
0.5 to 5 (inclusive), with steps of 0.5. The negative samples are reviews with a rating
of at most 2, and the positive ones are reviews with a rating of at least 4. The reviews
in between were discarded.

The original full dataset consists of 160,000 / 20,000 / 20,000 samples for training,
validation, and testing, respectively. We use 1,024 / 256 / 2,048 samples for training,
validation, and testing, respectively. All our splits are subsets of the original ones.

Here are a few examples from the training split:

```json
{
  "text": "Ce 7√®me volet ne m√©rite pas de notre part une grande attention, au vu du pr√©c√©dent New Police Story. √Ä la limite du huis clos, Jackie √©volue dans une bo√Æte de nuit, sorte de pi√®ge du m√©chant cherchant √† se venger, ou du moins √† d√©couvrir la v√©rit√© sur la mort de sa s≈ìur. Notre cascadeur acteur ne b√©n√©ficie pas d'un d√©cors √† la hauteur de son potentiel acrobatique et le film d'un sc√©nario √† la hauteur d'une production, et cette production d'une large distribution, ce qui explique son arriv√©e direct tout √©tag√®re.",
  "label": "negative"
}
```
```json
{
  "text": "Meme pour ceux qui n'aime pas les Chevaliers du Fiel allez voir. 1 il est meilleur que le 1 et cela est rare de voir une suite qui est meilleur que le 1. Des sc√®nes qui peuvent faire rire les petit et les grands. On ne s'ennuie pas. Super film allez le voir. L'interpretation des acteurs sont super. Bonne journ√©e",
  "label": "positive"
}
```
```json
{
  "text": "Une ambiance envo√ªtante, un r√©cit o√π se m√©langent sorcellerie, croyances indiennes, enqu√™te polici√®re sur fond de trafic de drogue, tout est conforme au livre de Tony Hillerman, m√™me si ce dernier a \"reni√©\" le film. Personnellement j'adore. H√©las introuvable en France et diffus√© seulement sur canal , il y a ..... un certain temps.",
  "label": "positive"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:
  ```
  Voici des textes et leur sentiment, qui peut √™tre 'positif' ou 'n√©gatif'.
  ```
- Base prompt template:
  ```
  Texte: {text}
  Sentiment: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Texte: {text}

  Classez le sentiment dans le texte. R√©pondez par ‚Äòpositif' ou ‚Äòn√©gatif'.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset allocine
```


## Named Entity Recognition

### ELTeC

This dataset was published in [this paper](https://doi.org/10.3828/mlo.v0i0.364) and
consists of sentences from 100 novels in French during the period 1840-1920, all of
which are in the public domain. These novels were automatically labelled with named
entities using Stanza-NER, and then manually corrected.

The original dataset consists of 100 samples, one for each novel. We split the novels
into sentences using the French NLTK sentence splitter, resulting in 4,815 samples. We
use 1,024 / 256 / 2,048 samples for training, validation, and testing, respectively.

We have furthermore converted the OntoNotes 5.0 labelling scheme to the CoNLL-2003
labelling scheme, which is more common in the NER literature. The mapping is as follows:

- `PERS` ‚û°Ô∏è `PER`
- `LOC` ‚û°Ô∏è `LOC`
- `ORG` ‚û°Ô∏è `ORG`
- `OTHER` ‚û°Ô∏è `MISC`
- `DEMO` ‚û°Ô∏è `O`
- `ROLE` ‚û°Ô∏è `O`
- `EVENT` ‚û°Ô∏è `O`

Here are a few examples from the training split:

```json
{
  'tokens': array(['Jamais', 'ils', 'ne', 'firent', 'de', 'provisions', ',', 'except√©', 'quelques', 'bottes', "d'ail", 'ou', "d'oignons", 'qui', 'ne', 'craignaient', 'rien', 'et', 'ne', 'co√ªtaient', 'pas', "grand'chose", ';', 'le', 'peu', 'de', 'bois', "qu'ils", 'consommaient', 'en', 'hiver', ',', 'la', 'Sauviat', "l'achetait", 'aux', 'fagotteurs', 'qui', 'passaient', ',', 'et', 'au', 'jour', 'le', 'jour', '.'], dtype=object),
  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)
}
```
```json
{
  'tokens': array(['I', 'Il', 'y', 'avait', 'plus', 'de', 'soixante', 'ans', 'que', "l'empereur", 'Napol√©on', ',', 'press√©', "d'argent", ',', 'avait', 'vendu', 'les', 'provinces', 'de', 'la', 'Louisiane', '√†', 'la', 'R√©publique', 'des', '√âtats-Unis', ';', 'mais', ',', 'en', 'd√©pit', 'de', "l'infiltration", 'yankee', ',', 'les', 'traditions', 'des', 'cr√©oles', 'fran√ßais', 'se', 'perp√©tuaient', '.'], dtype=object),
  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)
}
```
```json
{
  'tokens': array(['Les', 'fen√™tres', 'de', 'la', 'vieille', 'demeure', 'royale', ',', 'ordinairement', 'si', 'sombres', ',', '√©taient', 'ardemment', '√©clair√©es', ';', 'les', 'places', 'et', 'les', 'rues', 'attenantes', ',', 'habituellement', 'si', 'solitaires', ',', 'd√®s', 'que', 'neuf', 'heures', 'sonnaient', '√†', "Saint-Germain-l'Auxerrois", ',', '√©taient', ',', "quoiqu'il", 'f√ªt', 'minuit', ',', 'encombr√©es', 'de', 'populaire', '.'], dtype=object),
  'labels': array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:
  ```
  Vous trouverez ci-dessous des phrases et des dictionnaires JSON avec les entit√©s nomm√©es qui apparaissent dans la phrase donn√©e.
  ```
- Base prompt template:
  ```
  Sentence: {text}
  Entit√©s nomm√©es: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Sentence: {text}

  Identifiez les entit√©s nomm√©es dans la phrase. Vous devez produire ceci sous forme de dictionnaire JSON avec les cl√©s 'personne', 'lieu', 'organisation' et 'divers'. Les valeurs doivent √™tre des listes des entit√©s nomm√©es de ce type, exactement comme elles apparaissent dans la phrase.
  ```

- Label mapping:
    - `B-PER` ‚û°Ô∏è `personne`
    - `I-PER` ‚û°Ô∏è `personne`
    - `B-LOC` ‚û°Ô∏è `lieu`
    - `I-LOC` ‚û°Ô∏è `lieu`
    - `B-ORG` ‚û°Ô∏è `organisation`
    - `I-ORG` ‚û°Ô∏è `organisation`
    - `B-MISC` ‚û°Ô∏è `divers`
    - `I-MISC` ‚û°Ô∏è `divers`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset eltec
```


## Linguistic Acceptability

### ScaLA-fr

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [French Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_French-GSD/tree/master) by
assuming that the documents in the treebank are correct, and corrupting the samples to
create grammatically incorrect samples. The corruptions were done by either removing a
word from a sentence, or by swapping two neighbouring words in a sentence. To ensure
that this does indeed break the grammaticality of the sentence, a set of rules were used
on the part-of-speech tags of the words in the sentence.

The original dataset consists of 16,342 samples, from which we use 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
used as-is in the framework.

Here are a few examples from the training split:

```json
{
  "text": "Le dessert est une part minuscule de g√¢teau.",
  "label": "correct"
}
```
```json
{
  "text": "Le trafic international sera normal vendredi sur Eurostar, Thalys, et sur les trains √† grande vitesse √† destination de l', a indiqu√© la SNCF dans un communiqu√©.",
  "label": "incorrect"
}
```
```json
{
  "text": "Certains craignent qu' un avantage comp√©titif trop net et trop durable favorise les positions dominantes, monopoles et oligopoles, qui limitent la et concurrence finissent par peser sur le consommateur.",
  "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  Les phrases suivantes indiquent si elles sont grammaticalement correctes.
  ```
- Base prompt template:
  ```
  Phrase: {text}
  Correct du point de vue grammatical: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Phrase: {text}

  D√©terminez si la phrase est grammaticalement correcte ou non. R√©pondez par 'oui' si la phrase est correcte et par 'non' si elle ne l'est pas, et rien d'autre.
  ```
- Label mapping:
    - `correct` ‚û°Ô∏è `oui`
    - `incorrect` ‚û°Ô∏è `non`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset scala-fr
```


## Reading Comprehension

### FQuAD

This dataset was published in [this
paper](https://aclanthology.org/2020.findings-emnlp.107/), and is a manually annotated
dataset of questions and answers from the French Wikipedia.

The original full dataset consists of 20,731 / 3,188 / 2,189 samples for training,
validation and testing, respectively. Note that the testing split is not publicly
accessible, however, so we only use the training and validation split. We use 1,024 /
256 / 2,048 samples for training, validation, and testing, respectively. Our training
split is a subset of the original training split, and our validation and testing splits
are subsets of the original validation split.

Here are a few examples from the training split:

```json
{
  'context': "Parmi leurs th√®mes r√©currents, on en trouve qui sont communs √† beaucoup d'autres groupes contemporains ou plus anciens : les Stranglers ont d√©crit, √† plusieurs reprises, la vie d'un groupe de rock dans toutes ses dimensions (fans, autres groupes, vie en tourn√©e). Le th√®me rebattu - chez les groupes des ann√©es 1960-1970 - de la drogue, est abord√©e sur une demi-douzaine de chansons (Don't Bring Harry), tandis que la vision angoiss√©e du futur, dans le contexte de la guerre froide ou en lien avec les avanc√©es de la science, a donn√© lieu √† plusieurs titres (Curfew). On retrouve √©galement chez eux des pr√©occupations √©cologiques (Dreamtime) ou sociales. La guerre, notamment les deux guerres mondiales (Northwinds), mais aussi les guerres contemporaines (I Don't Agree), sont √† l'origine de divers textes. Mais le th√®me qui les a le plus inspir√©s, c'est de loin les femmes (The Man They Love to Hate).",
  'question': 'Sur combien de chanson le th√®me de la drogue est il abord√© ?',
  'answers': {
    'answer_start': array([353]),
    'text': array(['une demi-douzaine'], dtype=object)
  }
}
```
```json
{
  'context': "Au cours de cette p√©riode, Cavour se distingue par son talent de financier. Il contribue de mani√®re pr√©pond√©rante √† la fusion de la Banque de G√™nes et de la nouvelle Banque de Turin au sein de la Banque Nationale des √âtats sardes (Banca Nazionale degli Stati Sardi). Apr√®s le succ√®s √©lectoral de d√©cembre 1849, Cavour devient √©galement une des figures dominantes de la politique pi√©montaise et il prend la fonction de porte-parole de la majorit√© mod√©r√©e qui vient de se cr√©er. Fort de cette position, il fait valoir que le moment des r√©formes est arriv√©, favoris√© par le Statut albertin qui a cr√©√© de r√©elles perspectives de progr√®s. Le Pi√©mont peut ainsi s'√©loigner du front catholique et r√©actionnaire, qui triomphe dans le reste de l'Italie. ",
  'question': "En quel ann√©e sort-il vainqueur d'une √©lection ?",
  'answers': {
    'answer_start': array([305]),
    'text': array(['1849'], dtype=object)
  }
}
```
```json
{
  'context': "Pour autant, le ph√©nom√®ne m√©t√©orologique se d√©cline sous d'autres variantes : ocelles du paon, √©voquant les cent yeux d'Argus, fleurs champ√™tres et ornant les jardins o√π s'√©tablit l'osmose entre couleurs compl√©mentaires. La po√©sie tient en main la palette du peintre,, celle de Claude Gell√©e ou de Poussin. Pour autant, il ne s'agit pas l√† d'une posture habituelle chez lui, qui privil√©gie les paysages quasi-monochromes.",
  'question': "Qu'est ce que l'auteur pr√©f√®re d√©crire ?",
  'answers': {
    'answer_start': array([394]),
    'text': array(['paysages'], dtype=object)
  }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:
  ```
  Les textes suivants sont accompagn√©s de questions et de r√©ponses.
  ```
- Base prompt template:
  ```
  Texte: {text}
  Question: {question}
  R√©ponse en 3 mots maximum: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Texte: {text}

  R√©pondez √† la question suivante sur le texte ci-dessus en 3 mots maximum.

  Question: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset fquad
```


## Knowledge

### MMLU-fr

This dataset is a machine translated version of the English [MMLU
dataset](https://openreview.net/forum?id=d7KBjmI3GmQ) and features questions within 57
different topics, such as elementary mathematics, US history and law. The translation to
French was done by the University of Oregon as part of [this
paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 269 / 1,410 / 13,200 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
new and there can thus be some overlap between the original validation and test sets and
our validation and test sets.

Here are a few examples from the training split:

```json
{
  "text": "En 2013, la part des personnes en Ethiopie qui pensent que les partis politiques sont corrompus est\nChoix:\na. 24%\nb. 44%\nc. 64%\nd. 84%",
  "label": "a"
}
```
```json
{
  "text": "Combien de nombres entiers positifs et n√©gatifs $12$ est-il un multiple?\nChoix:\na. 3\nb. 12\nc. 4\nd. 6",
  "label": "b"
}
```
```json
{
  "text": "Quelle affirmation suivante concernant les r√©actions d√©pendantes de la lumi√®re de la photosynth√®se est correcte?\nChoix:\na. Ils fournissent le carbone qui est incorpor√© dans le sucre.\nb. Ils produisent du PGA, qui est converti en glucose par la fixation du carbone dans les r√©actions ind√©pendantes de la lumi√®re.\nc. L'eau est s√©par√©e en fournissant des ions hydrog√®ne et des √©lectrons √† la NADP pour un stockage temporaire.\nd. Ils se produisent dans le stroma des chloroplastes.",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  Les questions suivantes sont des questions √† choix multiples (avec r√©ponses).
  ```
- Base prompt template:
  ```
  Question: {text}
  Choix:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_c}
  R√©ponse: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Question: {text}
  Choix:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  R√©pondez √† la question ci-dessus par 'a', 'b', 'c' ou 'd', et rien d'autre.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset mmlu-fr
```


## Common-sense Reasoning

### HellaSwag-fr

This dataset is a machine translated version of the English [HellaSwag
dataset](https://aclanthology.org/P19-1472/). The original dataset was based on both
video descriptions from ActivityNet as well as how-to articles from WikiHow. The dataset
was translated by the University of Oregon as part of [this
paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 9,310 samples. We use a 1,024 / 256 / 2,048 split
for training, validation and testing, respectively (so 3,328 samples used in total).

Here are a few examples from the training split:

```json
{
  "text": "[header] Comment dire √† vos enfants que vous allez divorcer [title] Contr√¥lez vos √©motions. [step] Vos enfants seront probablement en col√®re et boulevers√©s lorsque vous leur annoncerez le divorce, essayez donc de ne pas r√©agir de la m√™me mani√®re. Attendez de rompre la nouvelle lorsque vous pourrez discuter du sujet de mani√®re efficace et rester ma√Ætre de vos √©motions.\nChoix:\na. Rappelez-vous, le but de la discussion est d'√™tre l√† pour les enfants - ils ne devraient pas avoir √† vous r√©conforter. [title] Essayez de le faire ensemble, si possible.\nb. [substeps] Trouvez un moyen d'√©viter que vos enfants ne vous agressent verbalement. Assurez-vous d'√™tre calme et pos√© et ne donnez pas l'impression que la nouvelle du divorce est quelque chose qui vous d√©range.\nc. [substeps] Si vos enfants ont du mal √† comprendre la nouvelle √† distance, posez-leur des questions lors d'une conversation intime et priv√©e. Laissez-les utiliser les questions pour traiter et comprendre ce qu'ils ressentent √† propos de l'annonce.\nd. [substeps] Si vous ne voulez pas qu'ils le sachent imm√©diatement, partez en silence et r√©fl√©chissez un peu plus longtemps avant de leur dire. Cherchez un endroit confortable pour vous deux pour parler en priv√©, afin que vous puissiez tous deux prendre du temps pour traiter vos sentiments et accepter la situation.",
  "label": "a"
}
```
```json
{
  "text": "Certains stands servent des hot-dogs aux gens alors qu'ils p√™chent sur la glace. Un petit gar√ßon et une petite fille tentent d'attraper un poisson. ils\nChoix:\na. attrapent un poisson et continuent de nager.\nb. sont interview√©s pendant qu'ils p√™chent.\nc. essaient √† plusieurs reprises, errant tout pr√®s de leur poisson.\nd. sont rapidement emport√©s par le courant alors qu'ils luttent pour s'√©loigner du banc de la rivi√®re et pagayent pour √©chapper √† de l√©g√®res infestations de poissons dans l'eau",
  "label": "b"
}
```
```json
{
  "text": "[header] Comment se calmer [title] Respirer. [step] Respirer. Lentement.\nChoix:\na. Concentrez-vous sur votre respiration et d√©tendez votre corps. Continuez √† inspirer et expirer lentement par le nez, en mettant une pression sur votre diaphragme et vos muscles fessiers (vos poumons).\nb. Si votre c≈ìur bat vite ou fort, vous pourriez √™tre en danger de tachycardie, d'AVC ou de toute autre crise cardiaque. [title] Allongez-vous sur le dos et inspirez et expirez profond√©ment.\nc. Inspirez pendant 5 secondes; retenez votre souffle pendant 5 secondes, puis expirez pendant 5 secondes. Cela fonctionne parce que vous faites l'oppos√© de ce qu'une personne excit√©e ferait.\nd. Inspirez pendant un compte de cinq et abaissez-vous. Expirez, expirez quatre fois de plus, aussi profond√©ment que vous pouvez sentir, et r√©p√©tez pour un total de dix.",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  Les questions suivantes sont des questions √† choix multiples (avec r√©ponses).
  ```
- Base prompt template:
  ```
  Question: {text}
  Choix:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_c}
  R√©ponse: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Question: {text}
  Choix:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  R√©pondez √† la question ci-dessus par 'a', 'b', 'c' ou 'd', et rien d'autre.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset hellaswag-fr
```


## Summarization

### Orange Sum

This dataset was published in [this
paper](https://aclanthology.org/2021.emnlp-main.740/) and consists of news articles from
[Orange Actu](https://actu.orange.fr/). The summaries were written by the journalists
themselves (the "abstract" field in the original dataset).

The original full dataset consists of 21,401 / 1,500 / 1,500 samples for training,
validation and testing, respectively. We use 1,024 / 256 / 1,024 samples for training,
validation, and testing, respectively. All our splits are subsets of the original ones.

Here are a few examples from the training split:

```json
{
  "text": "R√©clam√© puis annonc√© par Emmanuel Macron, le d√©bat parlementaire sur l'immigration s'est ouvert ce lundi 7 octobre avec une allocution d'Edouard Philippe devant les d√©put√©s. Le Premier ministre a commenc√© son discours en empruntant les mots d'un de ses pr√©d√©cesseurs, Michel Rocard. Il a ensuite fait √©tat d'un syst√®me fran√ßais d'asile \"satur√©\". \"En 2018, la France a enregistr√© le record de 123.000 demandes d'asile\", a t-il rappel√©, estimant que la France \"n'a pas atteint tous\" ses objectifs en mati√®re de politique migratoire et de lutte contre l'immigration irr√©guli√®re. \"La question d'un pilotage par objectifs de l'admission au s√©jour n'est pas tabou. Je n'ai pas peur de r√©fl√©chir √† l'id√©e de quotas. Il nous faut donc regarder sujet apr√®s sujet. On sait depuis longtemps que les quotas ne s'appliquent ni √† l'asile ni √† l'immigration familiale. Pour autant, celle-ci ne pourrait √©chapper √† toute ma√Ætrise. Il faut lutter contre les abus et les fraudes, et resserrer les crit√®res l√† o√π cela s'impose\" a t-il poursuivi.Le Premier ministre a en revanche balay√© l'id√©e de la fin du droit du sol, r√©clam√©e par des √©lus de droite. \"Je ne vois pas bien en quoi √† l'√©chelle du pays, la fin du droit du sol serait une r√©ponse\". Il a √©galement adress√© une critique virulente √† l'√©gard de la th√©orie de \"l'immigration de remplacement\", un \"vocable d'une laideur certaine qui fait appel aux ressorts les plus d√©testables du complotisme.Ces th√©ories \"inspiraient encore r√©cemment des discours dont j'ai eu l'occasion de dire qu'ils √©taient profond√©ment contraires √† l'id√©e dont nous nous faisons de la France et de la R√©publique\" a t-il encore ass√©n√©, en r√©f√©rence √† la r√©cente \"Convention de la droite\" organis√©e le 28 septembre dernier autour de Marion Mar√©chal et Eric Zemmour.",
  "target_text": "Le Premier ministre a ouvert ce lundi 7 octobre le d√©bat sur l'immigration √† l'Assembl√©e nationale, d√©clarant que le syst√®me fran√ßais d'asile est aujourd'hui \"satur√©\". Il a au passage pourfendu la th√©orie de \"l'immigration de remplacement\", qui fait selon lui appel \"aux ressorts les plus d√©testables du complotisme\"."
}
```
```json
{
  "text": "Un supermarch√© a √©t√© d√©truit par une explosion, samedi 2 janvier, √† Grasse, dans les Alpes-Maritimes, a rapport√© France 3. Aucun bless√© n'est √† d√©plorer.L'explosion s'est produite vers 6h du matin dans ce supermarch√© Aldi de Grasse. Elle a √©t√© suivie par un violent incendie. Le b√¢timent a √©t√© \"totalement d√©truit\", selon le maire de la ville, qui a √©voqu√© une cause \"accidentelle\" sur sa page Facebook. Une centaine de pompiers, ainsi que des policiers ont √©t√© mobilis√©s pour lutter contre le sinistre et s√©curiser le p√©rim√®tre.Selon Nice-Matin, deux employ√©es du supermarch√© ont √©t√© souffl√©es par l'explosion en allumant la lumi√®re au moment d'arriver sur leur lieu de travail. Aucune des deux n'a √©t√© bless√©e physiquement, mais elles sont tr√®s choqu√©es.Vers 9h, le feu √©tait ma√Ætris√©, a indiqu√© √† France 3 un porte-parole du Service d'incendie et de secours des Alpes-Maritimes. Soixante pompiers et 40 engins de secours √©taient toujours mobilis√©s sur place.",
  "target_text": "Une centaine de pompiers ont √©t√© mobilis√©s pour lutter contre l'incendie."
}
```
```json
{
  "text": "Trois ans et demi apr√®s la d√©cision des Britanniques de quitter l'Union europ√©enne, le Brexit est finalement intervenu vendredi 31 janvier. Une mesure qui va s√©rieusement changer la donne pour les Britanniques qui si√®gent aujourd'hui dans les conseils municipaux en France. Comme tous les citoyens europ√©ens, les Britanniques avaient jusqu'√† pr√©sent le droit de vote et d'√©ligibilit√© aux √©lections municipales fran√ßaises. Actuellement sur 2.493 conseillers √©trangers, 757 viennent du Royaume-Uni, soit environ 30%, selon le R√©pertoire national des √©lus. Ils sont nettement plus nombreux que les Belges (544 √©lus) et les Portugais (357). Ils r√©sident pour la plupart dans un grand quart Sud-Ouest de la France : Charente (70 √©lus), Dordogne (59), Aude (52), Haute-Vienne (40), Lot-et-Garonne (31), H√©rault (30), Deux S√®vres (28), Gers (26), Lot (23)...Or, avec le Brexit, ils ne pourront pas briguer de nouveau mandat, √† moins d'avoir acquis une autre nationalit√© europ√©enne depuis les derni√®res √©lections. C'est notamment le cas √† Poupas, village de 85 habitants dans le Tarn-et-Garonne, o√π deux des trois conseillers municipaux britanniques, sur les 11 au total que compte la commune, ont obtenu la nationalit√© fran√ßaise. Le droit \"de payer et de se taire\"Pour certaines petites communes, o√π il est souvent difficile de trouver des candidats, c'est un vrai casse-t√™te. √Ä Perriers-en-Beauficel, dans la Manche, Patrick Head , originaire du Wiltshire (sud de l'Angleterre), va ainsi terminer son mandat. Le sexag√©naire avait rafl√© pas moins de 89,74% des suffrages dans ce petit village normand, o√π il a √©lu domicile en 2004. Soit le meilleur score de cette commune de 216 habitants, o√π les √©lecteurs peuvent rayer ou ajouter un nom. \"√áa va nous manquer car Patrick nous aidait beaucoup\", regrette la maire Lydie Brionne, qui explique que son colistier faisait \"le lien\" avec la cinquantaine de Britanniques install√©s dans ce coin de campagne normande. √Ä Perriers-en-Beauficel, sur les onze √©lus de 2014, deux sont Britanniques. \"Il va falloir trouver deux nouveaux candidats. C'est difficile de trouver des gens motiv√©s dans une petite commune\", souligne la maire, par ailleurs √©leveuse de vaches laiti√®res. \"Depuis 20 ans, beaucoup de Britanniques se sont install√©s, ils ont repeupl√© la commune, √ßa a donn√© du dynamisme\", raconte l'√©lue. Avec le Brexit, \"j'ai peur qu'ils soient oblig√©s de repartir.\"Loin d'√™tre isol√©, le cas de ce village normand se retrouve partout o√π les Britanniques sont fortement implant√©s. √Ä Bellegarde-du-Raz√®s, commune de 240 habitants dans l'Aude, les deux √©lus d'Outre-Manche \"apportent une valeur ajout√©e\" au village, avec \"leur importante implication dans le milieu associatif\", estime le maire Gilbert De Paoli. L'√âcossaise Alisson Mackie, 63 ans, install√©e depuis 2011, est d√©pit√©e de ne plus pouvoir se repr√©senter en mars. \"On a construit notre maison ici, on paye des imp√¥ts ici, on consomme ici mais on a √©t√© ray√©s des listes √©lectorales\", d√©plore-t-elle.√Ä Jouac, village de 180 habitants en Haute-Vienne, la maire Virginie Windridge, 39 ans, elle-m√™me mari√©e √† un Britannique, trouve aussi \"tr√®s injuste que des gens qui sont l√† depuis des ann√©es, payent des imp√¥ts et contribuent √† la vie de la commune, aient du jour au lendemain le droit 'de payer et de se taire'\". \"C'est dur √† avaler\", dit-elle.Les deux √©lus britanniques actuels ont \"un apport important\", souligne la maire. \"D√©j√† ils sont un relais avec la communaut√© britannique de la commune. Et puis ils apportent des id√©es diff√©rentes, une autre fa√ßon de fonctionner, de voir les choses\", d√©crit Mme Windridge. \"Ils am√®nent parfois un regard sur ce qui existe ou se fait ailleurs, une autre perspective\". \"Et, il faut bien le dire, culturellement, quelquefois, les Britanniques sont plus ouverts aux changements que nous, ont un peu moins peur de l'inconnu\", ajoute-t-elle en donnant en exemple la d√©cision d'√©teindre l'√©clairage public nocturne. \"Les √©lus britanniques √©taient naturellement les plus ouverts sur cette id√©e-l√†, ils voyaient de suite le gagnant-gagnant, pour l'environnement et le budget de la commune\", estime-t-elle.",
  "target_text": "√Ä l'heure actuelle, plus de 750 Britanniques si√®gent dans les conseils municipaux en France. Or, avec la sortie du Royaume-Uni de l'Union europ√©enne, ils ne pourront pas se repr√©senter en mars prochain."
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 1
- Prefix prompt:
  ```
  Les articles suivants sont accompagn√©s d'un r√©sum√©.
  ```
- Base prompt template:
  ```
  Article de presse: {text}
  R√©sum√©: {target_text}
  ```
- Instruction-tuned prompt template:
  ```
  Article de presse: {text}

  R√©digez un r√©sum√© de l'article ci-dessus.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset orange-sum
```
