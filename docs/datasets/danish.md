# 游뾇릖 Danish

This is an overview of all the datasets used in the Danish part of ScandEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.


## Sentiment Classification

### Angry Tweeets

This dataset was published in [this
paper](https://aclanthology.org/2021.nodalida-main.53/) and was a crowd-sourcing effort
to annotate sentiment of Danish tweets.

The original full dataset consists of 3,458 samples, and we are using a split of 1,024 /
256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples
used in total). All the samples in the original test set are included in our test set,
but our test set is furthermore using a subset of the original training set as test
samples as well. The original dataset did not have a validation split, so we have
created one by sampling from the training set.

Here are a few examples from the training split:

```json
{
  "text": "Jeg tror, det der var kampen. Goff virker lost",
  "label": "negative"
}
```
```json
{
  "text": "@USER @USER Vi bruger ogs친 snildt 1-2 timer (nogle gange flere timer end det) p친 at putte den yngste. Det er oftest Tommi, som g칮r det, for jeg g친r helt amok i processen. S친 sm칮rer jeg madpakker og rydder op i stedet.",
  "label": "neutral"
}
```
```json
{
  "text": "Er du nysgerrig p친, hvordan du diskvalificerer dig selv fra at blive taget seri칮st i den offentlige debat? Naser har svaret. #dkpol #dkmedier [LINK]",
  "label": "negative"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  F칮lgende er tweets og deres sentiment, som kan v칝re 'positiv', 'neutral' eller 'negativ'.
  ```
- Base prompt template:
  ```
  Tweet: {text}
  Sentiment: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Tweet: {text}

  Klassificer sentimentet i tweetet. Svar kun med 'positiv', 'neutral' eller 'negativ'.
  ```
- Label mapping:
    - `positive` 俱뫮잺 `positiv`
    - `neutral` 俱뫮잺 `neutral`
    - `negative` 俱뫮잺 `negativ`

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset angry-tweeets
```


## Named Entity Recognition

### DANSK

This dataset was published in [this
paper](https://doi.org/10.3384/nejlt.2000-1533.2024.5249) and is a manually annotated
subset of [Danish Gigaword](https://aclanthology.org/2021.nodalida-main.46/) with the 18
different named entities, following the OntoNotes 5.0 scheme. It was annotated by 10
different annotators.

The original full dataset consists of 15,062 samples, and we are using a split of 1,024
/ 256 / 1,024 samples for training, validation and testing, respectively (so 2,304
samples used in total). All samples in the validation and test sets of our version also
belong to the original validation and test set, respectively.

We have furthermore converted the OntoNotes 5.0 labelling scheme to the CoNLL-2003
labelling scheme, which is more common in the NER literature. The mapping is as follows:

- `PERSON` 俱뫮잺 `PER`
- `LOCATION` 俱뫮잺 `LOC`
- `FACILITY` 俱뫮잺 `LOC`
- `GPE` 俱뫮잺 `LOC`
- `ORGANIZATION` 俱뫮잺 `PER`
- `EVENT` 俱뫮잺 `MISC`
- `LANGUAGE` 俱뫮잺 `MISC`
- `PRODUCT` 俱뫮잺 `MISC`
- `WORK OF ART` 俱뫮잺 `MISC`
- `NORP` 俱뫮잺 `MISC`
- `CARDINAL` 俱뫮잺 `O`
- `DATE` 俱뫮잺 `O`
- `LAW` 俱뫮잺 `O`
- `MONEY` 俱뫮잺 `O`
- `ORDINAL` 俱뫮잺 `O`
- `PERCENT` 俱뫮잺 `O`
- `QUANTITY` 俱뫮잺 `O`
- `TIME` 俱뫮잺 `O`

Here are a few examples from the training split:

```json
{
  "tokens": array(['I', 'dette', 'efter친r', 'har', 'Gr칮nland', 'taget', 'en', 'stor', 'beslutning', 'ved', 'folkeafstemningen', 'den', '25.', 'november', '.'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['칀h', ',', 'Petra', ',', 'vis', 'mig', 'din', 'krop', '.'], dtype=object),
  "labels": array(['O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['Fravalget', 'af', 'revision', 'registreres', 'automatisk', 'ved', 'anmeldelse', 'af', 'stiftelse', 'af', 'selskabet', 'hos', 'Erhvervs-styrelsen', '.'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O'], dtype=object)
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:
  ```
  F칮lgende er s칝tninger og JSON-ordb칮ger med de navngivne enheder, som forekommer i den givne s칝tning.
  ```
- Base prompt template:
  ```
  S칝tning: {text}
  Navngivne enheder: {label}
  ```
- Instruction-tuned prompt template:
  ```
  S칝tning: {text}

  Identific칠r de navngivne enheder i s칝tningen. Du skal outputte dette som en JSON-ordbog med n칮glerne 'person', 'sted', 'organisation' og 'diverse'. V칝rdierne skal v칝re lister over de navngivne enheder af den type, pr칝cis som de forekommer i s칝tningen.
  ```
- Label mapping:
    - `B-PER` 俱뫮잺 `person`
    - `I-PER` 俱뫮잺 `person`
    - `B-LOC` 俱뫮잺 `sted`
    - `I-LOC` 俱뫮잺 `sted`
    - `B-ORG` 俱뫮잺 `organisation`
    - `I-ORG` 俱뫮잺 `organisation`
    - `B-MISC` 俱뫮잺 `diverse`
    - `I-MISC` 俱뫮잺 `diverse`

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset dansk
```


### Unofficial: DaNE

This dataset was published in [this paper](https://aclanthology.org/2020.lrec-1.565/)
and is a manually NER annotated version of the [Danish Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Danish-DDT/tree/master). The NER
labels follow the CoNLL-2003 labelling scheme.

The original full dataset consists of 4,383 / 564 / 565 samples for training, validation
and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation
and testing, respectively (so 3,328 samples used in total). These splits are new and
there can thus be some overlap between the original validation and test sets and our
validation and test sets.

Here are a few examples from the training split:

```json
{
  "tokens": array(['Det', 'var', 'det', '친r', ',', 'hans', 'f칮rste', 'LP', ',', '"', 'With', 'A', 'Little', 'Help', 'From', 'My', 'Friends', '"', ',', 'udkom', '.'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['Eddie', 'Carbone', ',', 'italiensk-amerikansk', 'havnearbejder', 'i', 'New', 'York', '.'], dtype=object),
  "labels": array(['B-PER', 'I-PER', 'O', 'B-MISC', 'O', 'O', 'B-LOC', 'I-LOC', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['"', 'Jeg', 'er', 'mig', '!', '"', 'insisterer', 'han', 'under', 'det', 'flere', 'hundrede', '친r', 'gamle', 'egetr칝', ',', 'liggende', ',', 'som', 'den', 'popflab', 'han', 'er', ',', 'p친', 'ryggen', 'i', 'sine', 'orange', 'jeans', ',', 't-shirt', '-', 'som', 'naturligvis', 'stiller', 'et', 'solbrunt', 'beh친ret', 'bryst', 'til', 'skue', '-', 'et', 'par', '68er', '"', 'make', 'love', 'not', 'war', '"', 'solbriller', 'han', 'netop', 'har', 'k칮bt', 'i', 'Paris', ',', 'og', 'en', 'Kings', 'i', 'k칝ften', '.'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O'], dtype=object)
}
```


## Linguistic Acceptability

### ScaLA-da

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [Danish Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Danish-DDT/tree/master) by
assuming that the documents in the treebank are correct, and corrupting the samples to
create grammatically incorrect samples. The corruptions were done by either removing a
word from a sentence, or by swapping two neighbouring words in a sentence. To ensure
that this does indeed break the grammaticality of the sentence, a set of rules were used
on the part-of-speech tags of the words in the sentence.

The original full dataset consists of 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
used as-is in the framework.

Here are a few examples from the training split:

```json
{
  "text": "Samme dame dukkede netop nu op sammen med Odd-Catla's erkl칝rede yndling, v칝bneren Aikin af Cantir.",
  "label": "correct"
}
```
```json
{
  "text": "Gebyrets st칮rrelse afh칝nger nemlig af helt, i hvilken kategori den p친g칝ldende \"levnedsmiddelvirksomhed\" placeres.",
  "label": "incorrect"
}
```
```json
{
  "text": "Den statsansatte dyrl칝ge Kronf친gels p친 slagteri i Kristiansstad, Karl Erik Bj칮rkman, understreger, bel칝gningen hos producenten betyder meget for dyrenes trivsel:",
  "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  F칮lgende er s칝tninger og om de er grammatisk korrekte.
  ```
- Base prompt template:
  ```
  S칝tning: {text}
  Grammatisk korrekt: {label}
  ```
- Instruction-tuned prompt template:
  ```
  S칝tning: {text}

  Bestem om s칝tningen er grammatisk korrekt eller ej. Svar med 'ja', hvis s칝tningen er korrekt, og 'nej', hvis den ikke er.
  ```
- Label mapping:
    - `correct` 俱뫮잺 `ja`
    - `incorrect` 俱뫮잺 `nej`

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset scala-da
```


## Reading Comprehension

### ScandiQA-da

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the Danish part of the [MKQA
dataset](https://aclanthology.org/2021.tacl-1.82/). The MKQA dataset is based on the
English [Natural Questions dataset](https://aclanthology.org/Q19-1026/), based on search
queries from the Google search engine. The questions and answers were manually
translated to Danish (and other languages) as part of MKQA, and the contexts were in
ScandiQA-da machine translated using the [DeepL translation
API](https://www.deepl.com/en/pro-api/). A rule-based approach was used to ensure that
the translated contexts still contained the answer to the question, potentially by
changing the answers slightly.

The original full dataset consists of 6,810 / 500 / 500 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively (so 3,328 samples used in total). All validation
samples in our version also belong to the original validation set, and all original test
samples are included in our test set. The remaining 1,548 test samples in our version
was sampled from the original training set.

Here are a few examples from the training split:

```json
{
  "context": '"(Sittin\' On) The Dock of the Bay" er en sang, der er skrevet af soul-sangeren Otis Redding og guitaristen Steve Cropper sammen. Den blev indspillet af Redding to gange i 1967, herunder en gang f친 dage f칮r hans d칮d i et flystyrt. Sangen blev udgivet p친 Stax Records\' Volt-label i 1968 og blev den f칮rste posthume single, der l친 칮verst p친 hitlisterne i USA. Den n친ede op som nummer 3 p친 den britiske single-liste.',
  "question": 'Hvem sang sitting on the dock of the bay?',
  "answers": {
    "answer_start": array([79]),
    "text": array(['Otis Redding'], dtype=object)
  }
}
```
```json
{
  "context": "The Cat in the Hat Knows a Lot About That!\nKatten i hatten ved meget om det!\n\n\n\nKatten i hatten pilot\n\n\n\nGenre\nB칮rne-tv/undervisning/komedie\n\n\nInstrueret af\nTony Collingwood\n\n\nStemmer fra\nMartin Short\nJacob Ewaniuk\nAlexa Torrington\nRob Tinkler\n\n\nKomponist af temamusik\nDavid Schweitzer\n\n\nKomponist(er)\nDavid Schweitzer\n\n\nOprindelsesland\nCanada\nDet Forenede Kongerige\nUSA\n\n\nOprindelige sprog\nEngelsk\n\n\nAntal s칝soner\n2\n\n\nAntal episoder\n60 (liste over episoder)\n\n\nProduktion\n\n\nL칮betid\n30 minutter\n\n\nProduktionsselskab(er)\nCollingwood O'Hare Productions\nPortfolio Entertainment\nRandom House Children's Entertainment\nTreehouse TV\n\n\nDistribut칮r\nTreehouse TV\n\n\nUdgivelse\n\n\nOprindelige netv칝rk\nTreehouse TV (Canada)\nPBS Kids (USA)\nCITV og Tiny Pop (UK)\n\n\nBilledformat\n480i (SDTV)\n1080i (HDTV)\n\n\nOriginaludgivelse\n7. august 2010 (2010-08-07) - nu\n\n\nEksterne links\n\n\nWebsted\npbskids.org/catinthehat/",
  "question": 'Hvem synger titelmelodien til the cat in the hat?',
  "answers": {
    "answer_start": array([269]),
    "text": array(['David Schweitzer'], dtype=object)
  }
}
```
```json
{
  "context": 'Modern Slavery Act 2015\nLoven om moderne slaveri fra 2015 er en lov fra Det Forenede Kongeriges parlament. Den har til form친l at bek칝mpe slaveri i Det Forenede Kongerige og konsoliderer tidligere lovovertr칝delser vedr칮rende menneskehandel og slaveri. Loven g칝lder for England og Wales. Lovforslaget blev forelagt underhuset i udkast i oktober 2013 af James Brokenshire, parlamentarisk undersekret칝r for kriminalitet og sikkerhed, i oktober 2013. Lovforslagets sponsorer i indenrigsministeriet var Theresa May og Lord Bates. Det fik kongelig samstemmende udtalelse og blev lov den 26. marts 2015.',
  "question": 'Hvorn친r tr친dte den moderne slaveri i kraft?',
  "answers": {
    "answer_start": array([580]),
    "text": array(['26. marts 2015'], dtype=object)
  }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:
  ```
  F칮lgende er tekster med tilh칮rende sp칮rgsm친l og svar.
  ```
- Base prompt template:
  ```
  Tekst: {text}
  Sp칮rgsm친l: {question}
  Svar med maks. 3 ord: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Tekst: {text}

  Besvar f칮lgende sp칮rgsm친l om teksten ovenfor med maks. 3 ord.

  Sp칮rgsm친l: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset scandiqa-da
```


### Belebele-da

This dataset was published in [this paper](https://aclanthology.org/2024.acl-long.44/) and is a large-scale multilingual reading comprehension dataset covering 122 languages. The questions are generated from Wikipedia articles and are designed to test various aspects of reading comprehension, including factual understanding, inference, and numerical reasoning.

The original dataset provides test splits with human-verified question-answer pairs. We use a 256 / 64 / test_size split for training, validation and testing, respectively, where test_size is the remaining samples after filtering for length and repetitiveness. The questions are generated to be answerable from the given context and cover diverse topics from Wikipedia articles.

When evaluating generative models, we use the following setup (see the [methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F칮lgende er tekster med tilh칮rende multiple choice sp칮rgsm친l og svar.
  ```
- Base prompt template:
  ```
  {text}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  {text}

  Besvar ovenst친ende sp칮rgsm친l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset belebele-da
```


## Knowledge

### Danske Talem친der

This dataset was created by The Danish Language and Literature Society, published
[here](https://sprogteknologi.dk/dataset/1000-talemader-evalueringsdatasaet). The
dataset features Danish idioms along with their official meaning. For each idiom, three
negative samples were created: (a) a random idiom, (b) a concrete made-up idiom, and (c)
an abstract made-up idiom. The dataset was created to evaluate the ability of language
models to understand Danish idioms.

The original full dataset consists of 1,000 samples. We use a 128 / 64 / 808 split for
training, validation and testing, respectively (so 1,000 samples used in total).

Here are a few examples from the training split:

```json
{
  "text": "Hvilket af f칮lgende udtryk betyder 'tale nogen efter munden'?\nSvarmuligheder:\na. v칝re f칮jelig og give nogen ret selvom man ikke n칮dvendigvis er enig\nb. erkl칝re sig helt enig med en anden person\nc. sige det pr칝cis samme som en anden; efterabe\nd. v칝re egoistisk og sn칝versynet; kun t칝nke p친 sig selv",
  "label": "a"
}
```
```json
{
  "text": "Hvilket af f칮lgende udtryk betyder 'der falder en sten fra 칠ns hjerte'?\nSvarmuligheder:\na. en bestemt (kriminel, efters칮gt) person er forsvundet\nb. man bliver fri for en sorg eller bekymring; man bliver lettet\nc. man mister 칠n man har k칝r\nd. en sten forlader et hjerte man er i besiddelse af",
  "label": "b"
}
```
```json
{
  "text": "Hvilket af f칮lgende udtryk betyder 'have spidse albuer'?\nSvarmuligheder:\na. person der har det meget d친rligt fysisk og psykisk\nb. have ophobet vrede over l칝ngere tid\nc. h칝vde sig p친 andres bekostning\nd. have knogler der tr칝der tydeligt frem p친 ens albuer",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F칮lgende er multiple choice sp칮rgsm친l (med svar).
  ```
- Base prompt template:
  ```
  Hvad er betydningen af f칮lgende talem친de: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Hvad er betydningen af f칮lgende talem친de: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Besvar ovenst친ende sp칮rgsm친l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset danske-talemaader
```


### Danish Citizen Tests

This dataset was created by scraping the Danish citizenship tests (indf칮dsretspr칮ven)
and permanent residency tests (medborgerskabspr칮ven) from 2016 to 2023. These are
available on the [official website of the Danish Ministry of International Recruitment
and Integration](https://danskogproever.dk/).

The original full dataset consists of 720 samples. We use an 80 / 128 / 512 split for
training, validation and testing, respectively (so 720 samples used in total).

Here are a few examples from the training split:

```json
{
  "text": "Hvilke lande er med i rigsf칝llesskab et?\nSvarmuligheder:\na. Danmark, Gr칮nland og F칝r칮erne\nb. Danmark, Island og Norge",
  "label": "a"
}
```
```json
{
  "text": "Hvor mange medlemmer har Folketinget?\nSvarmuligheder:\na. 87\nb. 179\nc. 265",
  "label": "b"
}
```
```json
{
  "text": "Hvem kan blive biskop i den danske folkekirke?\nSvarmuligheder:\na. Kun m칝nd\nb. Kun kvinder\nc. B친de m 칝nd og kvinder",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F칮lgende er multiple choice sp칮rgsm친l (med svar).
  ```
- Base prompt template:
  ```
  Sp칮rgsm친l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Sp칮rgsm친l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}

  Besvar ovenst친ende sp칮rgsm친l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset danish-citizen-tests
```


### Unofficial: MMLU-da

This dataset is a machine translated version of the English [MMLU
dataset](https://openreview.net/forum?id=d7KBjmI3GmQ) and features questions within 57
different topics, such as elementary mathematics, US history and law. The translation to
Danish was done by the University of Oregon as part of [this
paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 269 / 1,410 / 13,200 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
new and there can thus be some overlap between the original validation and test sets and
our validation and test sets.

Here are a few examples from the training split:

```json
{
  "text": "Hvilket af f칮lgende coronavirusser har for친rsaget tusindvis af d칮dsfald over hele verden som en 'opst친et' virus?\nSvarmuligheder:\na. MERS\nb. SARS\nc. OC43\nd. HKU1",
  "label": "a"
}
```
```json
{
  "text": "Hvilken orbitale v칝g er mest sandsynligt at kollapse i en 'blow out' fraktur?\nSvarmuligheder:\na. Taget\nb. Gulvet\nc. Den laterale v칝g\nd. Den mediale v칝g",
  "label": "b"
}
```
```json
{
  "text": "Hvad er navnet p친 den st칮rste struktur i Teotihuac치n, og hvor mange platforme og pyramider blev bygget der?\nSvarmuligheder:\na. M친nepyramiden; 250\nb. Templet for den fjerkr칝kl칝dte slange; 400\nc. Solpyramiden; 600\nd. Inskriptionstemplen; 700",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F칮lgende er multiple choice sp칮rgsm친l (med svar).
  ```
- Base prompt template:
  ```
  Sp칮rgsm친l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Sp칮rgsm친l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Besvar ovenst친ende sp칮rgsm친l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```


### Unofficial: ARC-da

This dataset is a machine translated version of the English [ARC
dataset](https://doi.org/10.48550/arXiv.1803.05457) and features US grade-school science
questions. The translation to Danish was done by the University of Oregon as part of
[this paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 1,110 / 297 / 1,170 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 1,024 split for training,
validation and testing, respectively (so 2,304 samples used in total). All new splits
are subsets of the original splits.

Here are a few examples from the training split:

```json
{
  "text": "Et farmaceutisk firma har offentliggjort resultaterne af et begr칝nset eksperiment, der unders칮ger den beskyttende virkning af en kemisk forbindelse mod h칮je doser af UV-str친ler p친 hudceller. Senere blev det opdaget, at resultaterne ikke var reproducerbare. Hvilken handling kunne forskere fra firmaet have foretaget for at undg친 at offentligg칮re fejlagtige resultater?\nSvarmuligheder:\na. Udf칮r flere fors칮g.\nb. Brug kun lave niveauer af str친ling.\nc. Brug forskellige b칮lgel칝ngder af str친ling.\nd. Unders칮g resultaterne af lignende eksperimenter, f칮r man dannede en hypotese.",
  "label": "a"
}
```
```json
{
  "text": "En ingeni칮r skal beregne den potentielle energi af en rutschebanekabine 칮verst p친 en skr친ning. Hvilken information ville bedst hj칝lpe ingeni칮ren med at bestemme den potentielle energi af kabine?\nSvarmuligheder:\na. den afstand, som rutschebanekabinen skal rejse\nb. massen af rutschebanekabinen ved fuld kapacitet\nc. den gennemsnitlige v칝gt af en tom rutschebanekabine\nd. retningen, som rutschebanekabinen bev칝ger sig i",
  "label": "b"
}
```
```json
{
  "text": "En studerende h칝ldte vand i en plastbakke. Studerende satte derefter bakken i fryseren. Hvilken egenskab ved vand 칝ndrede sig, da vandet fryser?\nSvarmuligheder:\na. Vandet blev til en gas.\nb. Massen af vandet steg.\nc. Vandet tog en bestemt form.\nd. Smagen af vandet 칝ndrede sig ikke.",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F칮lgende er multiple choice sp칮rgsm친l (med svar).
  ```
- Base prompt template:
  ```
  Sp칮rgsm친l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_c}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Sp칮rgsm친l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Besvar ovenst친ende sp칮rgsm친l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```


## Common-sense Reasoning

### HellaSwag-da

This dataset is a machine translated version of the English [HellaSwag
dataset](https://aclanthology.org/P19-1472/). The original dataset was based on both
video descriptions from ActivityNet as well as how-to articles from WikiHow. The dataset
was translated by the University of Oregon as part of [this
paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 9,310 samples. We use a 1,024 / 256 / 2,048 split
for training, validation and testing, respectively (so 3,328 samples used in total).

Here are a few examples from the training split:

```json
{
  "text": "Disse mennesker tr칝der pedalerne med kun det ene ben og st친r midt p친 cyklen med det andet ben, der holder deres h칝nder oppe. n칝ste g칮r de\nSvarmuligheder:\na. en anden 칮velse, hvor de s칝tter det ene ben p친 pedalen, mens de har det andet ben ude og hopper op og ned.\nb. tager hinandens h칝nder og udf칮rer en eller anden dansebev칝gelse p친 b칮rsterne, som de bruger til at snurre rundt med deres kroppe og hoppe med h칝nderne oppe.\nc. drejer med deres forstenede h칝nder, laver en U-vending og starter derefter deres handlinger igen og igen.\nd. skifter til at st친 ved hj칝lp af to arme for at balancere sig selv.",
  "label": "a"
}
```
```json
{
  "text": "[header] S친dan dr칝ber du frugtfluer [title] Brug r친dden frugt. [step] Dit problem med frugtfluer begyndte sandsynligvis f칮rst, da du opdagede, at du havde efterladt nogle frugter, der til sidst blev r친dne. Brug den metode, der samlede fluene f칮rste gang til at fange dem igen, men denne gang f칮r dem til en mere morbide slutning.\nSvarmuligheder:\na. Dr칝b fluene ved at tr칝kke dem fra deres rede eller ved at bruge tunge k칝der med t칝nger til at fange dem og placere dem i en spand eller stuen. Du kan ogs친 bruge dyreaff칮ring s친som fiske- og ande-urin.\nb. Placer et stykke r친dden frugt i en sk친l og str칝k klart plastik over toppen. Sk칝r flere sm친 huller i plastikken med en tandstik og lad det st친 t칝t p친 stedet med fluene.\nc. Efter at have fors칮gt at fange dobbelt s친 mange fluer, som du kan, skal du fjerne de ubehagelige frugtstykker fra pakken og bage dem i 2-3 minutter. Fluene vil flyde 칮verst p친 den s칮de marmelade, n친r du fjerner frugten fra marmeladen.\nd. [substeps] Tjek d친ser for knotten, melbiller og fluer. K칮b blomster fra havecentret, hvis du ikke har al produktion i n칝rheden.",
  "label": "b"
}
```
```json
{
  "text": "En mand st친r indend칮rs p친 en platform foran tre tilskuere og l칮fter en tung v칝gtstang. En mand n칝rmer sig en v칝gtstang p친 gulvet og st친r foran den og forbereder sig p친 at l칮fte den. manden\nSvarmuligheder:\na. l칮fter v칝gtstangen, der h칝nger i luften p친 platformen, og vender sig mod tilskuerne.\nb. l칮fter v칝gtstangen og viser, hvordan han udf칮rer det, idet han pauser p친 hver stang for at m친le v칝gten.\nc. b칮jer sig derefter i kn칝ene og l칝gger h칝nderne p친 v칝gtens stangdel.\nd. l칮fter derefter klokken p친 sine skuldre, l칝ner sig tilbage, s칝tter armene bag hovedet og l칮fter den let.",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F칮lgende er multiple choice sp칮rgsm친l (med svar).
  ```
- Base prompt template:
  ```
  Sp칮rgsm친l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_c}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Sp칮rgsm친l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Besvar ovenst친ende sp칮rgsm친l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset hellaswag-da
```


## Summarization

### Nordjylland News

This dataset is based on news articles from the Danish news site [TV2
Nord](https://www.tv2nord.dk/), where the summaries are taken as the introductory
paragraphs of the articles.

The original full dataset consists of 75,200 samples. We use an 1,024 / 256 / 2,048
split for training, validation and testing, respectively (so 3,328 samples used in
total).

Here are a few examples from the training split:

```json
{
  "text": "Jacob Emil Andersen viste s칮ndag rundt p친 Halvorsminde Efterskole ved Hj칮rring. Skolen har ligget p친 samme sted siden 1903. Han er selv elev, da en IT-linje p친 skolen fangede hans interesse. - Det betyder meget for mig, jeg ville ikke have v칝ret lige s친 interesseret i den her skole, hvis der ikke havde v칝ret IT, fort칝ller Jacob Emil Andersen, der oprindeligt stammer fra Aalborg, til TV2 Nord. En af dem, han viser rundt til Efterskolernes dag, er Isabella Kristensen, der g친r i skole i Hune. Hun er p친 jagt efter noget helt specielt. - Helt sikkert dans, springgymnastik og fitness med noget puls, forklarer Isabella Kristensen til TV2 Nord. Netop efterskolernes specialisering er en af grundene til, at rekordmange v칝lger at bruge et 친r v칝k fra familien i 8.-, 9.- eller 10.-klasse. De s칝rlige linjefag har man flere af p친 Halvorsminde Efterskole. Jern og metal, arbejde med tr칝 og vinterbadning er blot nogle af de aktiviteter, eleverne kan st칮de ind i p친 de forskellige linjefag, som skolen tilbyder. Men efterskolerne skal ogs친 huske at have fokus p친 den faglighe kvalitet, lyder det fra forstanderen. - Vi skal v칝re skarpe p친 nogle nicheprodukter og nogle linjer med noget god kvalitet. S친 skal vi ogs친 lave god skole, fort칝ller forstander p친 Halvorsminde Efterskole, Jens Beermann, til TV2 Nord. Han bliver bakket op af sin kollega fra H칮rby Efterskole ved S칝by omkring 30 kilometer fra Halvorsminde. - N친r man laver sit valgfagsudbud, skal det ikke v칝re tilf칝ldigt. Man skal ikke t칝nke, at 'det er smart! Det m친 tr칝kke elever, det her!' Der skal v칝re en velovervejet refleksion i forhold til, om det passer ind i det, vi gerne vil som skole,, siger forstander p친 H칮rby Efterskole, Mogens Vesterg친rd, til TV2 Nord. Alene i Nordjylland gik mere end 2.000 elever p친 efterskole i skole친ret 2018-2019. B친de Halvorsminde Efterskole og H칮rby Skole har plads til 130 elever. Og noget tyder p친, at der i hvert fald er sikret en ny elev til n칝ste skole친r efter dagens 친bent hus. - Jeg synes at det ser sp칝ndende ud, og jeg har endnu mere lyst til at g친 her nu, siger Isabella Kristensen.",
  "target_text": "S칮ndag inviterede efterskoler landet over potentielle nye elever inden for. Efterskolerne specialiserer sig for at tiltr칝kke elever, men den gode faglighed m친 ikke blive glemt, lyder det fra nordjyske forstandere."
}
```
```json
{
  "text": "Efter en nat med spejl glatte veje i Nordjylland melder Nordjyllands Politi om en helt problemfri morgen. Selvom politikredse i TV2 Nords sendeomr친de melder om en rolig nat uden st칮rre uheld, s친 kan de bilister, der skal af sted l칮rdag morgen godt forvente lidt l칝ngere rejsetid. Der er nemlig stadig glatte veje, og der er faldet en del sne i Nordjylland. Saltvogne og sneplove har allerede v칝ret p친 vejene, og Politiet opfordre forsat bilisterne til at k칮re forsigtigt ude p친 de snefyldte veje.",
  "target_text": "Nordjyllands Politi melder om en stille morgen trods glatte veje og stort snefald i nat."
}
```
```json
{
  "text": "Det var meget t칝t p친 at g친 galt for en 10-친rig tysk dreng onsdag eftermiddag. Klokken 15:55 modtog alarmcentralen et opkald om en drengen, der var begravet i sand ved Vorup칮r Strand. - Nogle b칮rn legede p친 stranden, og her har de s친 gravet et hul ind i klitten. Det er s친 det, der er kollapset omkring drengen, fort칝ller vagtchef Carsten Henriksen ved Midt- og Vestjyllands Politi. Det vides ikke pr칝cist, hvor meget sand der v칝ltede ned over barnet, men det var nok til, at drengen ikke selv kunne komme fri. De tilstedev칝rende p친 stranden m친tte grave ham fri. Han var helt begravet i sand i omkring fem minutter. - Der var en tysk l칝ge p친 stranden, der kunne give f칮rstehj칝lp, indtil ambulancen kunne komme frem, fort칝ller vagtchefen. Drengen kom sig hurtigt og har det godt, men blev alligevel k칮rt til tjek p친 Aalborg Sygehus.",
  "target_text": "B칮rn p친 Vorup칮r Strand havde gravet et hul ind i klitterne, som kollapsede omkring en 10-친rig dreng."
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 1
- Prefix prompt:
  ```
  F칮lgende er nyhedsartikler med tilh칮rende resum칠er.
  ```
- Base prompt template:
  ```
  Nyhedsartikel: {text}
  Resum칠: {target_text}
  ```
- Instruction-tuned prompt template:
  ```
  Nyhedsartikel: {text}

  Skriv et resum칠 af ovenst친ende artikel.
  ```

You can evaluate this dataset directly as follows:

```bash
$ scandeval --model <model-id> --dataset nordjylland-news
```
