# üá©üá∞ Danish

This is an overview of all the datasets used in the Danish part of EuroEval. The
datasets are grouped by their task - see the [task overview](/tasks) for more
information about what these constitute.


## Sentiment Classification

### Angry Tweeets

This dataset was published in [this
paper](https://aclanthology.org/2021.nodalida-main.53/) and was a crowd-sourcing effort
to annotate sentiment of Danish tweets.

The original full dataset consists of 3,458 samples, and we are using a split of 1,024 /
256 / 2,048 samples for training, validation and testing, respectively (so 3,328 samples
used in total). All the samples in the original test set are included in our test set,
but our test set is furthermore using a subset of the original training set as test
samples as well. The original dataset did not have a validation split, so we have
created one by sampling from the training set.

Here are a few examples from the training split:

```json
{
  "text": "Jeg tror, det der var kampen. Goff virker lost",
  "label": "negative"
}
```
```json
{
  "text": "@USER @USER Vi bruger ogs√• snildt 1-2 timer (nogle gange flere timer end det) p√• at putte den yngste. Det er oftest Tommi, som g√∏r det, for jeg g√•r helt amok i processen. S√• sm√∏rer jeg madpakker og rydder op i stedet.",
  "label": "neutral"
}
```
```json
{
  "text": "Er du nysgerrig p√•, hvordan du diskvalificerer dig selv fra at blive taget seri√∏st i den offentlige debat? Naser har svaret. #dkpol #dkmedier [LINK]",
  "label": "negative"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  F√∏lgende er tweets og deres sentiment, som kan v√¶re 'positiv', 'neutral' eller 'negativ'.
  ```
- Base prompt template:
  ```
  Tweet: {text}
  Sentiment: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Tweet: {text}

  Klassificer sentimentet i tweetet. Svar kun med 'positiv', 'neutral' eller 'negativ'.
  ```
- Label mapping:
    - `positive` ‚û°Ô∏è `positiv`
    - `neutral` ‚û°Ô∏è `neutral`
    - `negative` ‚û°Ô∏è `negativ`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset angry-tweeets
```


## Named Entity Recognition

### DANSK

This dataset was published in [this
paper](https://doi.org/10.3384/nejlt.2000-1533.2024.5249) and is a manually annotated
subset of [Danish Gigaword](https://aclanthology.org/2021.nodalida-main.46/) with the 18
different named entities, following the OntoNotes 5.0 scheme. It was annotated by 10
different annotators.

The original full dataset consists of 15,062 samples, and we are using a split of 1,024
/ 256 / 1,024 samples for training, validation and testing, respectively (so 2,304
samples used in total). All samples in the validation and test sets of our version also
belong to the original validation and test set, respectively.

We have furthermore converted the OntoNotes 5.0 labelling scheme to the CoNLL-2003
labelling scheme, which is more common in the NER literature. The mapping is as follows:

- `PERSON` ‚û°Ô∏è `PER`
- `LOCATION` ‚û°Ô∏è `LOC`
- `FACILITY` ‚û°Ô∏è `LOC`
- `GPE` ‚û°Ô∏è `LOC`
- `ORGANIZATION` ‚û°Ô∏è `PER`
- `EVENT` ‚û°Ô∏è `MISC`
- `LANGUAGE` ‚û°Ô∏è `MISC`
- `PRODUCT` ‚û°Ô∏è `MISC`
- `WORK OF ART` ‚û°Ô∏è `MISC`
- `NORP` ‚û°Ô∏è `MISC`
- `CARDINAL` ‚û°Ô∏è `O`
- `DATE` ‚û°Ô∏è `O`
- `LAW` ‚û°Ô∏è `O`
- `MONEY` ‚û°Ô∏è `O`
- `ORDINAL` ‚û°Ô∏è `O`
- `PERCENT` ‚û°Ô∏è `O`
- `QUANTITY` ‚û°Ô∏è `O`
- `TIME` ‚û°Ô∏è `O`

Here are a few examples from the training split:

```json
{
  "tokens": array(['I', 'dette', 'efter√•r', 'har', 'Gr√∏nland', 'taget', 'en', 'stor', 'beslutning', 'ved', 'folkeafstemningen', 'den', '25.', 'november', '.'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['√Öh', ',', 'Petra', ',', 'vis', 'mig', 'din', 'krop', '.'], dtype=object),
  "labels": array(['O', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['Fravalget', 'af', 'revision', 'registreres', 'automatisk', 'ved', 'anmeldelse', 'af', 'stiftelse', 'af', 'selskabet', 'hos', 'Erhvervs-styrelsen', '.'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O'], dtype=object)
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 8
- Prefix prompt:
  ```
  F√∏lgende er s√¶tninger og JSON-ordb√∏ger med de navngivne enheder, som forekommer i den givne s√¶tning.
  ```
- Base prompt template:
  ```
  S√¶tning: {text}
  Navngivne enheder: {label}
  ```
- Instruction-tuned prompt template:
  ```
  S√¶tning: {text}

  Identific√©r de navngivne enheder i s√¶tningen. Du skal outputte dette som en JSON-ordbog med n√∏glerne 'person', 'sted', 'organisation' og 'diverse'. V√¶rdierne skal v√¶re lister over de navngivne enheder af den type, pr√¶cis som de forekommer i s√¶tningen.
  ```
- Label mapping:
    - `B-PER` ‚û°Ô∏è `person`
    - `I-PER` ‚û°Ô∏è `person`
    - `B-LOC` ‚û°Ô∏è `sted`
    - `I-LOC` ‚û°Ô∏è `sted`
    - `B-ORG` ‚û°Ô∏è `organisation`
    - `I-ORG` ‚û°Ô∏è `organisation`
    - `B-MISC` ‚û°Ô∏è `diverse`
    - `I-MISC` ‚û°Ô∏è `diverse`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset dansk
```


### Unofficial: DaNE

This dataset was published in [this paper](https://aclanthology.org/2020.lrec-1.565/)
and is a manually NER annotated version of the [Danish Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Danish-DDT/tree/master). The NER
labels follow the CoNLL-2003 labelling scheme.

The original full dataset consists of 4,383 / 564 / 565 samples for training, validation
and testing, respectively. We use a 1,024 / 256 / 2,048 split for training, validation
and testing, respectively (so 3,328 samples used in total). These splits are new and
there can thus be some overlap between the original validation and test sets and our
validation and test sets.

Here are a few examples from the training split:

```json
{
  "tokens": array(['Det', 'var', 'det', '√•r', ',', 'hans', 'f√∏rste', 'LP', ',', '"', 'With', 'A', 'Little', 'Help', 'From', 'My', 'Friends', '"', ',', 'udkom', '.'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['Eddie', 'Carbone', ',', 'italiensk-amerikansk', 'havnearbejder', 'i', 'New', 'York', '.'], dtype=object),
  "labels": array(['B-PER', 'I-PER', 'O', 'B-MISC', 'O', 'O', 'B-LOC', 'I-LOC', 'O'], dtype=object)
}
```
```json
{
  "tokens": array(['"', 'Jeg', 'er', 'mig', '!', '"', 'insisterer', 'han', 'under', 'det', 'flere', 'hundrede', '√•r', 'gamle', 'egetr√¶', ',', 'liggende', ',', 'som', 'den', 'popflab', 'han', 'er', ',', 'p√•', 'ryggen', 'i', 'sine', 'orange', 'jeans', ',', 't-shirt', '-', 'som', 'naturligvis', 'stiller', 'et', 'solbrunt', 'beh√•ret', 'bryst', 'til', 'skue', '-', 'et', 'par', '68er', '"', 'make', 'love', 'not', 'war', '"', 'solbriller', 'han', 'netop', 'har', 'k√∏bt', 'i', 'Paris', ',', 'og', 'en', 'Kings', 'i', 'k√¶ften', '.'], dtype=object),
  "labels": array(['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O'], dtype=object)
}
```


## Linguistic Acceptability

### ScaLA-da

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the [Danish Universal Dependencies
treebank](https://github.com/UniversalDependencies/UD_Danish-DDT/tree/master) by
assuming that the documents in the treebank are correct, and corrupting the samples to
create grammatically incorrect samples. The corruptions were done by either removing a
word from a sentence, or by swapping two neighbouring words in a sentence. To ensure
that this does indeed break the grammaticality of the sentence, a set of rules were used
on the part-of-speech tags of the words in the sentence.

The original dataset consists of 5,512 samples, from which we use 1,024 / 256 / 2,048 samples for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
used as-is in the framework.

Here are a few examples from the training split:

```json
{
  "text": "Samme dame dukkede netop nu op sammen med Odd-Catla's erkl√¶rede yndling, v√¶bneren Aikin af Cantir.",
  "label": "correct"
}
```
```json
{
  "text": "Gebyrets st√∏rrelse afh√¶nger nemlig af helt, i hvilken kategori den p√•g√¶ldende \"levnedsmiddelvirksomhed\" placeres.",
  "label": "incorrect"
}
```
```json
{
  "text": "Den statsansatte dyrl√¶ge Kronf√•gels p√• slagteri i Kristiansstad, Karl Erik Bj√∏rkman, understreger, bel√¶gningen hos producenten betyder meget for dyrenes trivsel:",
  "label": "incorrect"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 12
- Prefix prompt:
  ```
  F√∏lgende er s√¶tninger og om de er grammatisk korrekte.
  ```
- Base prompt template:
  ```
  S√¶tning: {text}
  Grammatisk korrekt: {label}
  ```
- Instruction-tuned prompt template:
  ```
  S√¶tning: {text}

  Bestem om s√¶tningen er grammatisk korrekt eller ej. Svar med 'ja', hvis s√¶tningen er korrekt, og 'nej', hvis den ikke er.
  ```
- Label mapping:
    - `correct` ‚û°Ô∏è `ja`
    - `incorrect` ‚û°Ô∏è `nej`

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset scala-da
```


## Reading Comprehension

### ScandiQA-da

This dataset was published in [this paper](https://aclanthology.org/2023.nodalida-1.20/)
and was automatically created from the Danish part of the [MKQA
dataset](https://aclanthology.org/2021.tacl-1.82/). The MKQA dataset is based on the
English [Natural Questions dataset](https://aclanthology.org/Q19-1026/), based on search
queries from the Google search engine. The questions and answers were manually
translated to Danish (and other languages) as part of MKQA, and the contexts were in
ScandiQA-da machine translated using the [DeepL translation
API](https://www.deepl.com/en/pro-api/). A rule-based approach was used to ensure that
the translated contexts still contained the answer to the question, potentially by
changing the answers slightly.

The original full dataset consists of 6,810 / 500 / 500 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively (so 3,328 samples used in total). All validation
samples in our version also belong to the original validation set, and all original test
samples are included in our test set. The remaining 1,548 test samples in our version
was sampled from the original training set.

Here are a few examples from the training split:

```json
{
  "context": '"(Sittin\' On) The Dock of the Bay" er en sang, der er skrevet af soul-sangeren Otis Redding og guitaristen Steve Cropper sammen. Den blev indspillet af Redding to gange i 1967, herunder en gang f√• dage f√∏r hans d√∏d i et flystyrt. Sangen blev udgivet p√• Stax Records\' Volt-label i 1968 og blev den f√∏rste posthume single, der l√• √∏verst p√• hitlisterne i USA. Den n√•ede op som nummer 3 p√• den britiske single-liste.',
  "question": 'Hvem sang sitting on the dock of the bay?',
  "answers": {
    "answer_start": array([79]),
    "text": array(['Otis Redding'], dtype=object)
  }
}
```
```json
{
  "context": "The Cat in the Hat Knows a Lot About That!\nKatten i hatten ved meget om det!\n\n\n\nKatten i hatten pilot\n\n\n\nGenre\nB√∏rne-tv/undervisning/komedie\n\n\nInstrueret af\nTony Collingwood\n\n\nStemmer fra\nMartin Short\nJacob Ewaniuk\nAlexa Torrington\nRob Tinkler\n\n\nKomponist af temamusik\nDavid Schweitzer\n\n\nKomponist(er)\nDavid Schweitzer\n\n\nOprindelsesland\nCanada\nDet Forenede Kongerige\nUSA\n\n\nOprindelige sprog\nEngelsk\n\n\nAntal s√¶soner\n2\n\n\nAntal episoder\n60 (liste over episoder)\n\n\nProduktion\n\n\nL√∏betid\n30 minutter\n\n\nProduktionsselskab(er)\nCollingwood O'Hare Productions\nPortfolio Entertainment\nRandom House Children's Entertainment\nTreehouse TV\n\n\nDistribut√∏r\nTreehouse TV\n\n\nUdgivelse\n\n\nOprindelige netv√¶rk\nTreehouse TV (Canada)\nPBS Kids (USA)\nCITV og Tiny Pop (UK)\n\n\nBilledformat\n480i (SDTV)\n1080i (HDTV)\n\n\nOriginaludgivelse\n7. august 2010 (2010-08-07) - nu\n\n\nEksterne links\n\n\nWebsted\npbskids.org/catinthehat/",
  "question": 'Hvem synger titelmelodien til the cat in the hat?',
  "answers": {
    "answer_start": array([269]),
    "text": array(['David Schweitzer'], dtype=object)
  }
}
```
```json
{
  "context": 'Modern Slavery Act 2015\nLoven om moderne slaveri fra 2015 er en lov fra Det Forenede Kongeriges parlament. Den har til form√•l at bek√¶mpe slaveri i Det Forenede Kongerige og konsoliderer tidligere lovovertr√¶delser vedr√∏rende menneskehandel og slaveri. Loven g√¶lder for England og Wales. Lovforslaget blev forelagt underhuset i udkast i oktober 2013 af James Brokenshire, parlamentarisk undersekret√¶r for kriminalitet og sikkerhed, i oktober 2013. Lovforslagets sponsorer i indenrigsministeriet var Theresa May og Lord Bates. Det fik kongelig samstemmende udtalelse og blev lov den 26. marts 2015.',
  "question": 'Hvorn√•r tr√•dte den moderne slaveri i kraft?',
  "answers": {
    "answer_start": array([580]),
    "text": array(['26. marts 2015'], dtype=object)
  }
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 4
- Prefix prompt:
  ```
  F√∏lgende er tekster med tilh√∏rende sp√∏rgsm√•l og svar.
  ```
- Base prompt template:
  ```
  Tekst: {text}
  Sp√∏rgsm√•l: {question}
  Svar med maks. 3 ord: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Tekst: {text}

  Besvar f√∏lgende sp√∏rgsm√•l om teksten ovenfor med maks. 3 ord.

  Sp√∏rgsm√•l: {question}
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset scandiqa-da
```


## Knowledge

### Danske Talem√•der

This dataset was created by The Danish Language and Literature Society, published
[here](https://sprogteknologi.dk/dataset/1000-talemader-evalueringsdatasaet). The
dataset features Danish idioms along with their official meaning. For each idiom, three
negative samples were created: (a) a random idiom, (b) a concrete made-up idiom, and (c)
an abstract made-up idiom. The dataset was created to evaluate the ability of language
models to understand Danish idioms.

The original full dataset consists of 1,000 samples. We use a 128 / 64 / 808 split for
training, validation and testing, respectively (so 1,000 samples used in total).

Here are a few examples from the training split:

```json
{
  "text": "Hvad betyder udtrykket 'tale nogen efter munden'?\nSvarmuligheder:\na. v√¶re f√∏jelig og give nogen ret selvom man ikke n√∏dvendigvis er enig\nb. erkl√¶re sig helt enig med en anden person\nc. sige det pr√¶cis samme som en anden; efterabe\nd. v√¶re egoistisk og sn√¶versynet; kun t√¶nke p√• sig selv",
  "label": "a"
}
```
```json
{
  "text": "Hvad betyder udtrykket 'der falder en sten fra √©ns hjerte'?\nSvarmuligheder:\na. en bestemt (kriminel, efters√∏gt) person er forsvundet\nb. man bliver fri for en sorg eller bekymring; man bliver lettet\nc. man mister √©n man har k√¶r\nd. en sten forlader et hjerte man er i besiddelse af",
  "label": "b"
}
```
```json
{
  "text": "Hvad betyder udtrykket 'have spidse albuer'?\nSvarmuligheder:\na. person der har det meget d√•rligt fysisk og psykisk\nb. have ophobet vrede over l√¶ngere tid\nc. h√¶vde sig p√• andres bekostning\nd. have knogler der tr√¶der tydeligt frem p√• ens albuer",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F√∏lgende er multiple choice sp√∏rgsm√•l (med svar).
  ```
- Base prompt template:
  ```
  Hvad er betydningen af f√∏lgende talem√•de: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Hvad er betydningen af f√∏lgende talem√•de: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Besvar ovenst√•ende sp√∏rgsm√•l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset danske-talemaader
```


### Danish Citizen Tests

This dataset was created by scraping the Danish citizenship tests (indf√∏dsretspr√∏ven)
and permanent residency tests (medborgerskabspr√∏ven) from 2016 to 2024. These are
available on the [official website of the Danish Ministry of International Recruitment
and Integration](https://danskogproever.dk/).

The original full dataset consists of 870 samples. We use an 345 / 90 / 525 split for
training, validation and testing, respectively. Here all the citizenship tests belong to
the test split, as well as the newest permanent residency tests. The validation split
contains the newer permanent residency tests after the ones in the test split, and the
training split contains the oldest permanent residency tests.

Here are a few examples from the training split:

```json
{
  "text": "Hvilket parti tilh√∏rte Lars L√∏kke Rasmussen, da han var statsminister i perioderne 2009-11 og 2015-19?\nSvarmuligheder:\na. Venstre\nb. Socialdemokratiet\nc. Det Konservative Folkeparti",
  "label": "a"
}
```
```json
{
  "text": "Hvilket af f√∏lgende omr√•der har kommunerne ansvaret for driften af?\nSvarmuligheder:\na. Domstole\nb. Vuggestuer\nc. Sygehuse",
  "label": "b"
}```
```json
{
  "text": "Hvilken organisation blev Danmark medlem af i 1945?\nSvarmuligheder:\na. Verdenshandelsorganisationen (WTO)\nb. Den Europ√¶iske Union (EU)\nc. De Forenede Nationer (FN)",
  "label": "c"
}```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F√∏lgende er multiple choice sp√∏rgsm√•l (med svar).
  ```
- Base prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}

  Besvar ovenst√•ende sp√∏rgsm√•l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset danish-citizen-tests
```


### Unofficial: MMLU-da

This dataset is a machine translated version of the English [MMLU
dataset](https://openreview.net/forum?id=d7KBjmI3GmQ) and features questions within 57
different topics, such as elementary mathematics, US history and law. The translation to
Danish was done by the University of Oregon as part of [this
paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 269 / 1,410 / 13,200 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 2,048 split for training,
validation and testing, respectively (so 3,328 samples used in total). These splits are
new and there can thus be some overlap between the original validation and test sets and
our validation and test sets.

Here are a few examples from the training split:

```json
{
  "text": "Hvilket af f√∏lgende coronavirusser har for√•rsaget tusindvis af d√∏dsfald over hele verden som en 'opst√•et' virus?\nSvarmuligheder:\na. MERS\nb. SARS\nc. OC43\nd. HKU1",
  "label": "a"
}
```
```json
{
  "text": "Hvilken orbitale v√¶g er mest sandsynligt at kollapse i en 'blow out' fraktur?\nSvarmuligheder:\na. Taget\nb. Gulvet\nc. Den laterale v√¶g\nd. Den mediale v√¶g",
  "label": "b"
}
```
```json
{
  "text": "Hvad er navnet p√• den st√∏rste struktur i Teotihuac√°n, og hvor mange platforme og pyramider blev bygget der?\nSvarmuligheder:\na. M√•nepyramiden; 250\nb. Templet for den fjerkr√¶kl√¶dte slange; 400\nc. Solpyramiden; 600\nd. Inskriptionstemplen; 700",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F√∏lgende er multiple choice sp√∏rgsm√•l (med svar).
  ```
- Base prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Besvar ovenst√•ende sp√∏rgsm√•l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```


### Unofficial: ARC-da

This dataset is a machine translated version of the English [ARC
dataset](https://doi.org/10.48550/arXiv.1803.05457) and features US grade-school science
questions. The translation to Danish was done by the University of Oregon as part of
[this paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 1,110 / 297 / 1,170 samples for training,
validation and testing, respectively. We use a 1,024 / 256 / 1,024 split for training,
validation and testing, respectively (so 2,304 samples used in total). All new splits
are subsets of the original splits.

Here are a few examples from the training split:

```json
{
  "text": "Et farmaceutisk firma har offentliggjort resultaterne af et begr√¶nset eksperiment, der unders√∏ger den beskyttende virkning af en kemisk forbindelse mod h√∏je doser af UV-str√•ler p√• hudceller. Senere blev det opdaget, at resultaterne ikke var reproducerbare. Hvilken handling kunne forskere fra firmaet have foretaget for at undg√• at offentligg√∏re fejlagtige resultater?\nSvarmuligheder:\na. Udf√∏r flere fors√∏g.\nb. Brug kun lave niveauer af str√•ling.\nc. Brug forskellige b√∏lgel√¶ngder af str√•ling.\nd. Unders√∏g resultaterne af lignende eksperimenter, f√∏r man dannede en hypotese.",
  "label": "a"
}
```
```json
{
  "text": "En ingeni√∏r skal beregne den potentielle energi af en rutschebanekabine √∏verst p√• en skr√•ning. Hvilken information ville bedst hj√¶lpe ingeni√∏ren med at bestemme den potentielle energi af kabine?\nSvarmuligheder:\na. den afstand, som rutschebanekabinen skal rejse\nb. massen af rutschebanekabinen ved fuld kapacitet\nc. den gennemsnitlige v√¶gt af en tom rutschebanekabine\nd. retningen, som rutschebanekabinen bev√¶ger sig i",
  "label": "b"
}
```
```json
{
  "text": "En studerende h√¶ldte vand i en plastbakke. Studerende satte derefter bakken i fryseren. Hvilken egenskab ved vand √¶ndrede sig, da vandet fryser?\nSvarmuligheder:\na. Vandet blev til en gas.\nb. Massen af vandet steg.\nc. Vandet tog en bestemt form.\nd. Smagen af vandet √¶ndrede sig ikke.",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F√∏lgende er multiple choice sp√∏rgsm√•l (med svar).
  ```
- Base prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_c}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Besvar ovenst√•ende sp√∏rgsm√•l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```


## Common-sense Reasoning

### HellaSwag-da

This dataset is a machine translated version of the English [HellaSwag
dataset](https://aclanthology.org/P19-1472/). The original dataset was based on both
video descriptions from ActivityNet as well as how-to articles from WikiHow. The dataset
was translated by the University of Oregon as part of [this
paper](https://aclanthology.org/2023.emnlp-demo.28/), using GPT-3.5-turbo.

The original full dataset consists of 9,310 samples. We use a 1,024 / 256 / 2,048 split
for training, validation and testing, respectively (so 3,328 samples used in total).

Here are a few examples from the training split:

```json
{
  "text": "Disse mennesker tr√¶der pedalerne med kun det ene ben og st√•r midt p√• cyklen med det andet ben, der holder deres h√¶nder oppe. n√¶ste g√∏r de\nSvarmuligheder:\na. en anden √∏velse, hvor de s√¶tter det ene ben p√• pedalen, mens de har det andet ben ude og hopper op og ned.\nb. tager hinandens h√¶nder og udf√∏rer en eller anden dansebev√¶gelse p√• b√∏rsterne, som de bruger til at snurre rundt med deres kroppe og hoppe med h√¶nderne oppe.\nc. drejer med deres forstenede h√¶nder, laver en U-vending og starter derefter deres handlinger igen og igen.\nd. skifter til at st√• ved hj√¶lp af to arme for at balancere sig selv.",
  "label": "a"
}
```
```json
{
  "text": "[header] S√•dan dr√¶ber du frugtfluer [title] Brug r√•dden frugt. [step] Dit problem med frugtfluer begyndte sandsynligvis f√∏rst, da du opdagede, at du havde efterladt nogle frugter, der til sidst blev r√•dne. Brug den metode, der samlede fluene f√∏rste gang til at fange dem igen, men denne gang f√∏r dem til en mere morbide slutning.\nSvarmuligheder:\na. Dr√¶b fluene ved at tr√¶kke dem fra deres rede eller ved at bruge tunge k√¶der med t√¶nger til at fange dem og placere dem i en spand eller stuen. Du kan ogs√• bruge dyreaff√∏ring s√•som fiske- og ande-urin.\nb. Placer et stykke r√•dden frugt i en sk√•l og str√¶k klart plastik over toppen. Sk√¶r flere sm√• huller i plastikken med en tandstik og lad det st√• t√¶t p√• stedet med fluene.\nc. Efter at have fors√∏gt at fange dobbelt s√• mange fluer, som du kan, skal du fjerne de ubehagelige frugtstykker fra pakken og bage dem i 2-3 minutter. Fluene vil flyde √∏verst p√• den s√∏de marmelade, n√•r du fjerner frugten fra marmeladen.\nd. [substeps] Tjek d√•ser for knotten, melbiller og fluer. K√∏b blomster fra havecentret, hvis du ikke har al produktion i n√¶rheden.",
  "label": "b"
}
```
```json
{
  "text": "En mand st√•r indend√∏rs p√• en platform foran tre tilskuere og l√∏fter en tung v√¶gtstang. En mand n√¶rmer sig en v√¶gtstang p√• gulvet og st√•r foran den og forbereder sig p√• at l√∏fte den. manden\nSvarmuligheder:\na. l√∏fter v√¶gtstangen, der h√¶nger i luften p√• platformen, og vender sig mod tilskuerne.\nb. l√∏fter v√¶gtstangen og viser, hvordan han udf√∏rer det, idet han pauser p√• hver stang for at m√•le v√¶gten.\nc. b√∏jer sig derefter i kn√¶ene og l√¶gger h√¶nderne p√• v√¶gtens stangdel.\nd. l√∏fter derefter klokken p√• sine skuldre, l√¶ner sig tilbage, s√¶tter armene bag hovedet og l√∏fter den let.",
  "label": "c"
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 5
- Prefix prompt:
  ```
  F√∏lgende er multiple choice sp√∏rgsm√•l (med svar).
  ```
- Base prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_c}
  Svar: {label}
  ```
- Instruction-tuned prompt template:
  ```
  Sp√∏rgsm√•l: {text}
  Svarmuligheder:
  a. {option_a}
  b. {option_b}
  c. {option_c}
  d. {option_d}

  Besvar ovenst√•ende sp√∏rgsm√•l ved at svare med 'a', 'b', 'c' eller 'd', og intet andet.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset hellaswag-da
```


## Summarization

### Nordjylland News

This dataset is based on news articles from the Danish news site [TV2
Nord](https://www.tv2nord.dk/), where the summaries are taken as the introductory
paragraphs of the articles.

The original full dataset consists of 75,200 samples. We use an 1,024 / 256 / 2,048
split for training, validation and testing, respectively (so 3,328 samples used in
total).

Here are a few examples from the training split:

```json
{
  "text": "Jacob Emil Andersen viste s√∏ndag rundt p√• Halvorsminde Efterskole ved Hj√∏rring. Skolen har ligget p√• samme sted siden 1903. Han er selv elev, da en IT-linje p√• skolen fangede hans interesse. -¬†Det betyder meget for mig, jeg ville ikke have v√¶ret lige s√• interesseret¬†i den her skole, hvis der ikke havde v√¶ret IT, fort√¶ller Jacob Emil Andersen, der oprindeligt stammer fra Aalborg, til TV2 Nord. En af dem, han viser rundt til Efterskolernes dag, er Isabella Kristensen, der g√•r i skole i Hune. Hun er p√• jagt efter noget helt specielt. -¬†Helt sikkert dans, springgymnastik og fitness med noget puls, forklarer Isabella Kristensen til TV2 Nord. Netop efterskolernes specialisering er en af grundene til, at rekordmange v√¶lger at bruge et √•r v√¶k fra familien i 8.-, 9.- eller 10.-klasse. De s√¶rlige linjefag har man flere af p√• Halvorsminde Efterskole. Jern og metal, arbejde med tr√¶ og vinterbadning er blot nogle af de aktiviteter, eleverne kan st√∏de ind i p√• de forskellige linjefag, som skolen tilbyder. Men efterskolerne skal ogs√• huske at have fokus p√• den¬†faglighe kvalitet,¬†lyder det fra forstanderen. -¬†Vi skal v√¶re skarpe p√• nogle nicheprodukter og nogle linjer med noget god kvalitet. S√• skal vi ogs√• lave god skole, fort√¶ller¬†forstander p√• Halvorsminde Efterskole, Jens Beermann, til TV2 Nord. Han bliver bakket op af sin kollega fra H√∏rby Efterskole ved S√¶by omkring 30 kilometer fra Halvorsminde. - N√•r man laver sit valgfagsudbud, skal det ikke v√¶re tilf√¶ldigt. Man skal ikke t√¶nke, at ‚Äôdet er smart! Det m√• tr√¶kke elever, det her!‚Äô Der skal v√¶re en velovervejet refleksion i forhold til, om det passer ind i det, vi gerne vil som skole,, siger forstander p√• H√∏rby Efterskole, Mogens Vesterg√•rd, til TV2 Nord. Alene i Nordjylland gik mere end 2.000 elever p√• efterskole i skole√•ret 2018-2019. B√•de Halvorsminde Efterskole og H√∏rby Skole har plads til 130 elever. Og noget tyder p√•, at der i hvert fald er sikret en ny¬†elev til n√¶ste skole√•r efter dagens √•bent hus. -¬†Jeg synes at det ser sp√¶ndende ud, og jeg har endnu mere lyst til at g√• her nu, siger Isabella Kristensen.",
  "target_text": "S√∏ndag inviterede efterskoler landet over potentielle nye elever inden for. Efterskolerne specialiserer sig for at tiltr√¶kke elever, men den gode faglighed m√• ikke blive glemt, lyder det fra nordjyske forstandere."
}
```
```json
{
  "text": "Efter en nat med spejl glatte veje i Nordjylland melder Nordjyllands Politi om en helt problemfri morgen.¬†Selvom politikredse i TV2 Nords sendeomr√•de melder om en rolig nat uden st√∏rre uheld, s√•¬†kan de bilister, der skal af sted l√∏rdag morgen godt forvente¬†lidt l√¶ngere rejsetid. Der er nemlig stadig glatte veje, og der er faldet en del sne i Nordjylland.¬†Saltvogne og sneplove har allerede v√¶ret p√• vejene, og Politiet opfordre forsat bilisterne til at k√∏re forsigtigt ude p√• de snefyldte veje.",
  "target_text": "Nordjyllands Politi melder om en stille morgen trods glatte veje og stort snefald i nat."
}
```
```json
{
  "text": "Det var meget t√¶t p√• at g√• galt for en 10-√•rig tysk dreng onsdag eftermiddag. Klokken 15:55 modtog alarmcentralen et opkald om en drengen, der var begravet i sand ved Vorup√∏r Strand. - Nogle b√∏rn legede p√• stranden, og her har de s√• gravet et hul ind i klitten. Det er s√• det, der er kollapset omkring drengen, fort√¶ller vagtchef Carsten Henriksen ved Midt- og Vestjyllands Politi. Det vides ikke pr√¶cist, hvor meget sand der v√¶ltede ned over barnet, men det var nok til, at drengen ikke selv kunne komme fri. De tilstedev√¶rende p√• stranden m√•tte grave ham fri. Han var¬†helt begravet i sand i omkring fem minutter. - Der var en tysk l√¶ge p√• stranden, der kunne give f√∏rstehj√¶lp, indtil ambulancen kunne komme frem, fort√¶ller vagtchefen. Drengen kom sig hurtigt og har det godt, men blev alligevel k√∏rt til tjek p√• Aalborg Sygehus.",
  "target_text": "B√∏rn p√• Vorup√∏r Strand havde gravet et hul ind i klitterne, som kollapsede omkring en 10-√•rig dreng."
}
```

When evaluating generative models, we use the following setup (see the
[methodology](/methodology) for more information on how these are used):

- Number of few-shot examples: 1
- Prefix prompt:
  ```
  F√∏lgende er nyhedsartikler med tilh√∏rende resum√©er.
  ```
- Base prompt template:
  ```
  Nyhedsartikel: {text}
  Resum√©: {target_text}
  ```
- Instruction-tuned prompt template:
  ```
  Nyhedsartikel: {text}

  Skriv et resum√© af ovenst√•ende artikel.
  ```

You can evaluate this dataset directly as follows:

```bash
$ euroeval --model <model-id> --dataset nordjylland-news
```
